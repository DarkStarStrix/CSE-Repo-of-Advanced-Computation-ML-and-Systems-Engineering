{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8150308,"sourceType":"datasetVersion","datasetId":4820237}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":8.358169,"end_time":"2024-04-18T17:38:35.290676","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-18T17:38:26.932507","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step 1: Import libraries ","metadata":{"papermill":{"duration":0.005065,"end_time":"2024-04-18T17:38:30.641508","exception":false,"start_time":"2024-04-18T17:38:30.636443","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom tqdm import tqdm\nfrom wordcloud import WordCloud\nimport seaborn as sns","metadata":{"papermill":{"duration":0.005279,"end_time":"2024-04-18T17:38:32.08363","exception":false,"start_time":"2024-04-18T17:38:32.078351","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2025-02-06T00:21:56.241713Z","iopub.execute_input":"2025-02-06T00:21:56.242490Z","iopub.status.idle":"2025-02-06T00:21:56.247027Z","shell.execute_reply.started":"2025-02-06T00:21:56.242461Z","shell.execute_reply":"2025-02-06T00:21:56.246167Z"},"trusted":true},"outputs":[],"execution_count":100},{"cell_type":"code","source":"def setup_environment():\n    \"\"\"Initialize environment settings and check GPU\"\"\"\n    torch.manual_seed(42)\n    np.random.seed(42)\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f'Using device: {device}')\n    return device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T00:21:34.245066Z","iopub.execute_input":"2025-02-06T00:21:34.245356Z","iopub.status.idle":"2025-02-06T00:21:34.252318Z","shell.execute_reply.started":"2025-02-06T00:21:34.245324Z","shell.execute_reply":"2025-02-06T00:21:34.251350Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"# ## 2. Data Loading\ndef load_data():\n    \"\"\"Load and combine datasets from Kaggle paths\"\"\"\n    # Load individual datasets\n    education = pd.read_csv(\"/kaggle/input/sentiment-analysis-evaluation-dataset/Education.csv\")\n    finance = pd.read_csv(\"/kaggle/input/sentiment-analysis-evaluation-dataset/Finance.csv\")\n    politics = pd.read_csv(\"/kaggle/input/sentiment-analysis-evaluation-dataset/Politics.csv\")\n    sports = pd.read_csv(\"/kaggle/input/sentiment-analysis-evaluation-dataset/Sports.csv\")\n    \n    # Create source labels\n    education['source'] = 'Education'\n    finance['source'] = 'Finance'\n    politics['source'] = 'Politics'\n    sports['source'] = 'Sports'\n    \n    # Combine all dataframes\n    df = pd.concat([education, finance, politics, sports], ignore_index=True)\n    \n    # Shuffle the dataset\n    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n    \n    return df\n\n# Execute data loading\ndf = load_data()\nprint(\"Dataset loaded successfully!\")\nprint(\"\\nFirst few rows:\")\ndisplay(df.head())\nprint(\"\\nDataset Info:\")\ndisplay(df.info())\n\n# Display category distribution\nprint(\"\\nSamples per category:\")\ndisplay(df['source'].value_counts())\nprint(\"Available columns in the dataframe:\")\nprint(df.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T00:21:34.253718Z","iopub.execute_input":"2025-02-06T00:21:34.254034Z","iopub.status.idle":"2025-02-06T00:21:34.293996Z","shell.execute_reply.started":"2025-02-06T00:21:34.254015Z","shell.execute_reply":"2025-02-06T00:21:34.293149Z"}},"outputs":[{"name":"stdout","text":"Dataset loaded successfully!\n\nFirst few rows:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                Text     Label     source\n0  Education policies should be informed by resea...  positive  Education\n1  Sports endorsements by celebrities and athlete...  positive     Sports\n2  The pursuit of short-term profits can lead to ...  negative    Finance\n3  Sports broadcasting has become saturated with ...  negative     Sports\n4  Credit rating agencies are susceptible to conf...  negative    Finance","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Education policies should be informed by resea...</td>\n      <td>positive</td>\n      <td>Education</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sports endorsements by celebrities and athlete...</td>\n      <td>positive</td>\n      <td>Sports</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The pursuit of short-term profits can lead to ...</td>\n      <td>negative</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sports broadcasting has become saturated with ...</td>\n      <td>negative</td>\n      <td>Sports</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Credit rating agencies are susceptible to conf...</td>\n      <td>negative</td>\n      <td>Finance</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nDataset Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 209 entries, 0 to 208\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   Text    209 non-null    object\n 1   Label   209 non-null    object\n 2   source  209 non-null    object\ndtypes: object(3)\nmemory usage: 5.0+ KB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"name":"stdout","text":"\nSamples per category:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"source\nSports       56\nPolitics     53\nEducation    52\nFinance      48\nName: count, dtype: int64"},"metadata":{}},{"name":"stdout","text":"Available columns in the dataframe:\n['Text', 'Label', 'source']\n","output_type":"stream"}],"execution_count":97},{"cell_type":"code","source":"# ## 3. Exploratory Data Analysis\n\ndef plot_sentiment_distributions(df):\n    \"\"\"Plot overall and category-wise sentiment distributions.\"\"\"\n    # Overall distribution\n    plt.figure(figsize=(12, 6))\n    sns.countplot(data=df, x='Label')\n    plt.title('Distribution of Sentiments Across All Categories')\n    plt.show()\n\n\ndef create_word_clouds(df):\n    \"\"\"Create word clouds for each sentiment category.\"\"\"\n    plt.figure(figsize=(15, 5))\n    \n    for idx, sentiment in enumerate(['positive', 'negative', 'neutral']):\n        plt.subplot(1, 3, idx + 1)\n        text = ' '.join(df[df['Label'] == sentiment]['Text'])  # Updated column names\n        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.title(f'{sentiment.capitalize()} Sentiment Word Cloud')\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T00:21:34.294863Z","iopub.execute_input":"2025-02-06T00:21:34.295092Z","iopub.status.idle":"2025-02-06T00:21:34.301173Z","shell.execute_reply.started":"2025-02-06T00:21:34.295075Z","shell.execute_reply":"2025-02-06T00:21:34.300336Z"}},"outputs":[],"execution_count":98},{"cell_type":"code","source":"# ## 4. Data Preparation\n\n# %%\nclass SentimentDataset(Dataset):\n    \"\"\"Custom Dataset class for BERT input\"\"\"\n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n        \n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n# Prepare data for modeling\nsentiment_map = {'positive': 0, 'neutral': 1, 'negative': 2}\ndf['label'] = df['positive', 'negative', 'neutral'].map(sentiment_map)\n\n# Split data\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    df['text'].values, df['label'].values, \n    test_size=0.2, random_state=42\n)\n\n# Initialize tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained(\n    'bert-base-uncased', \n    num_labels=3\n).to(device)\n\n# Create datasets\ntrain_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\nval_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n\n# Create dataloaders\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)\n\nprint(\"Data preparation completed!\")\nprint(f\"Training samples: {len(train_dataset)}\")\nprint(f\"Validation samples: {len(val_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T00:23:06.968893Z","iopub.execute_input":"2025-02-06T00:23:06.969275Z","iopub.status.idle":"2025-02-06T00:23:07.062936Z","shell.execute_reply.started":"2025-02-06T00:23:06.969247Z","shell.execute_reply":"2025-02-06T00:23:07.061758Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: ('positive', 'negative', 'neutral')","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[101], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Prepare data for modeling\u001b[39;00m\n\u001b[1;32m     36\u001b[0m sentiment_map \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n\u001b[0;32m---> 37\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpositive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnegative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneutral\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmap(sentiment_map)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[1;32m     40\u001b[0m train_texts, val_texts, train_labels, val_labels \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m     41\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, \n\u001b[1;32m     42\u001b[0m     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     43\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: ('positive', 'negative', 'neutral')"],"ename":"KeyError","evalue":"('positive', 'negative', 'neutral')","output_type":"error"}],"execution_count":101},{"cell_type":"code","source":"# ## 5. Model Training\n\n# %%\ndef train_model(model, train_loader, val_loader, device, epochs=3):\n    \"\"\"Train the model and return training history\"\"\"\n    optimizer = AdamW(model.parameters(), lr=2e-5)\n    \n    train_losses = []\n    val_losses = []\n    \n    for epoch in range(epochs):\n        # Training phase\n        model.train()\n        total_train_loss = 0\n        \n        for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs}'):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            total_train_loss += loss.item()\n            \n            loss.backward()\n            optimizer.step()\n        \n        avg_train_loss = total_train_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        \n        # Validation phase\n        model.eval()\n        total_val_loss = 0\n        \n        with torch.no_grad():\n            for batch in val_loader:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['labels'].to(device)\n                \n                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n                total_val_loss += outputs.loss.item()\n        \n        avg_val_loss = total_val_loss / len(val_loader)\n        val_losses.append(avg_val_loss)\n        \n        print(f'Epoch {epoch + 1}:')\n        print(f'Average training loss: {avg_train_loss:.4f}')\n        print(f'Average validation loss: {avg_val_loss:.4f}')\n    \n    return train_losses, val_losses\n\n# Execute training\ntrain_losses, val_losses = train_model(model, train_loader, val_loader, device)\n\n# %%\ndef plot_training_history(train_losses, val_losses):\n    \"\"\"Plot training and validation loss curves\"\"\"\n    plt.figure(figsize=(10, 6))\n    plt.plot(train_losses, label='Training Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n# Plot training history\nplot_training_history(train_losses, val_losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T00:21:34.399633Z","iopub.status.idle":"2025-02-06T00:21:34.400021Z","shell.execute_reply.started":"2025-02-06T00:21:34.399821Z","shell.execute_reply":"2025-02-06T00:21:34.399838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ## 6. Model Evaluation\n\n# %%\ndef evaluate_model(model, val_loader, device):\n    \"\"\"Evaluate model performance\"\"\"\n    model.eval()\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = model(input_ids, attention_mask=attention_mask)\n            preds = torch.argmax(outputs.logits, dim=1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    return all_preds, all_labels\n\n# Execute evaluation\npredictions, true_labels = evaluate_model(model, val_loader, device)\n\n# %%\ndef print_classification_metrics(true_labels, predictions):\n    \"\"\"Print classification report\"\"\"\n    print(\"Classification Report:\")\n    print(classification_report(true_labels, predictions, \n                              target_names=['Positive', 'Neutral', 'Negative']))\n\n# Print metrics\nprint_classification_metrics(true_labels, predictions)\n\n# %%\ndef plot_confusion_matrix(true_labels, predictions):\n    \"\"\"Plot confusion matrix\"\"\"\n    plt.figure(figsize=(8, 6))\n    cm = confusion_matrix(true_labels, predictions)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=['Positive', 'Neutral', 'Negative'],\n                yticklabels=['Positive', 'Neutral', 'Negative'])\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()\n\n# Plot confusion matrix\nplot_confusion_matrix(true_labels, predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T00:21:34.401630Z","iopub.status.idle":"2025-02-06T00:21:34.401925Z","shell.execute_reply.started":"2025-02-06T00:21:34.401793Z","shell.execute_reply":"2025-02-06T00:21:34.401804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ## 7. Save Model and Make Predictions\n\n# %%\n# Save the model\nmodel_save_path = 'sentiment_model'\nmodel.save_pretrained(model_save_path)\ntokenizer.save_pretrained(model_save_path)\nprint(f\"Model saved to {model_save_path}\")\n\n# %%\ndef predict_sentiment(text, model, tokenizer, device):\n    \"\"\"Predict sentiment for a given text\"\"\"\n    model.eval()\n    encoding = tokenizer.encode_plus(\n        text,\n        add_special_tokens=True,\n        max_length=128,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n    \n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n        pred = torch.argmax(outputs.logits, dim=1)\n    \n    sentiment_map = {0: 'positive', 1: 'neutral', 2: 'negative'}\n    return sentiment_map[pred.item()]\n\n# Test the prediction function\nexample_texts = [\n    \"This product exceeded my expectations!\",\n    \"The service was okay, nothing special.\",\n    \"I'm very disappointed with this purchase.\"\n]\n\nprint(\"Example predictions:\")\nfor text in example_texts:\n    prediction = predict_sentiment(text, model, tokenizer, device)\n    print(f\"\\nText: {text}\")\n    print(f\"Predicted sentiment: {prediction}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T00:21:34.402622Z","iopub.status.idle":"2025-02-06T00:21:34.402894Z","shell.execute_reply.started":"2025-02-06T00:21:34.402765Z","shell.execute_reply":"2025-02-06T00:21:34.402777Z"}},"outputs":[],"execution_count":null}]}